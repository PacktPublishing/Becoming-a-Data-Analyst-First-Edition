{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833502af",
   "metadata": {},
   "source": [
    "### Standardizing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with inconsistent date formats\n",
    "df = pd.DataFrame({'date': ['2022-08-01', '01/08/2022', 'August 1, 2022']})\n",
    "\n",
    "# Convert the date column to a uniform format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62eb0f",
   "metadata": {},
   "source": [
    "### Converting currency symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with inconsistent currency formats\n",
    "df = pd.DataFrame({'price': ['$100', '€200', '£300']})\n",
    "\n",
    "# Remove currency symbols and convert to float\n",
    "df['price'] = df['price'].replace({'\\$': '', '€': '', '£': ''}, regex=True).astype(float)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4dcb5",
   "metadata": {},
   "source": [
    "### Standardize phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba345960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with inconsistent phone number formats\n",
    "df = pd.DataFrame({'phone': ['123-456-7890', '(123) 456-7890', '123.456.7890']})\n",
    "\n",
    "# Standardize phone numbers to a consistent format\n",
    "df['phone'] = df['phone'].replace(r'[^\\d]', '', regex=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399772e9",
   "metadata": {},
   "source": [
    "### Misspelled categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a845b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with misspelled categories\n",
    "df = pd.DataFrame({'category': ['Appl', 'Orang', 'Bnan', 'Appl']})\n",
    "\n",
    "# Define a mapping to correct the spellings\n",
    "corrections = {'Appl': 'Apple', 'Orang': 'Orange', 'Bnan': 'Banana'}\n",
    "\n",
    "# Apply the mapping to correct the misspellings\n",
    "df['category'] = df['category'].map(corrections).fillna(df['category'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f700c",
   "metadata": {},
   "source": [
    "### Using fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "# Create DataFrame with misspelled cities\n",
    "df = pd.DataFrame({'city': ['Nw York', 'Sn Francisco', 'Chcago']})\n",
    "\n",
    "# List of correct city names\n",
    "correct_names = ['New York', 'San Francisco', 'Chicago']\n",
    "\n",
    "# Correct misspellings using fuzzy matching\n",
    "df['city'] = df['city'].apply(lambda x: process.extractOne(x, correct_names)[0])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f1f0d",
   "metadata": {},
   "source": [
    "### Misspelled product names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with incorrect product names\n",
    "df = pd.DataFrame({'product': ['Laptoop', 'Smarttphone', 'Tablett']})\n",
    "\n",
    "# Define specific corrections\n",
    "corrections = {'Laptoop': 'Laptop', 'Smarttphone': 'Smartphone', 'Tablett': 'Tablet'}\n",
    "\n",
    "# Replace incorrect product names with correct ones\n",
    "df['product'] = df['product'].replace(corrections)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e81da0",
   "metadata": {},
   "source": [
    "### Removing all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452287ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with duplicate records\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 3], 'B': [5, 6, 6, 7]})\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f65b2e",
   "metadata": {},
   "source": [
    "### Removing duplicates based on a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82214ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with duplicate records in specific column\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 3], 'B': [5, 6, 6, 7]})\n",
    "\n",
    "# Remove duplicates based on column 'A'\n",
    "df = df.drop_duplicates(subset=['A'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea72fc",
   "metadata": {},
   "source": [
    "### Last occurrence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, 2, 3], 'B': [5, 6, 6, 7]})\n",
    "\n",
    "# Remove duplicates but keep the last occurrence\n",
    "df = df.drop_duplicates(keep='last')\n",
    "print(df)ample 3: Keeping last occurrence of duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51ee90",
   "metadata": {},
   "source": [
    "### Removal of all missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating data with missing values\n",
    "data = {\n",
    "    'Age': [25, 30, None, 22],\n",
    "    'Income': [50000, 70000, 80000, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Removing rows with any missing values\n",
    "df_removed = df.dropna()\n",
    "print(df_removed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c0670",
   "metadata": {},
   "source": [
    "### Mean imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Creating data with missing values\n",
    "data = {\n",
    "    'Age': [25, 30, None, 22],\n",
    "    'Income': [50000, 70000, 80000, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Using mean imputation for missing values\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "df_mean_imputed = pd.DataFrame(mean_imputer.fit_transform(df), columns=df.columns)\n",
    "print(df_mean_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ef798",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sample time series data with missing values\n",
    "date_rng = pd.date_range(start='2021-01-01', end='2021-01-10', freq='D')\n",
    "data = {\n",
    "    'date': date_rng,\n",
    "    'temperature': [25, 28, np.nan, 27, 24, np.nan, 23, 22, 20, 19]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Setting the date column as the index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Using linear interpolation to fill missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36b88b",
   "metadata": {},
   "source": [
    "### Using KNN for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d120cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Creating data with missing values\n",
    "data_with_missing = {\n",
    "    'Feature1': [2, 4, None, 5],\n",
    "    'Feature2': [3, 1, 2, None]\n",
    "}\n",
    "df_missing = pd.DataFrame(data_with_missing)\n",
    "\n",
    "# Imputing missing values using K-Nearest Neighbors\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df_missing), columns=df_missing.columns)\n",
    "print(df_knn_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051f691",
   "metadata": {},
   "source": [
    "### Removing Duplicates Based on a Specific Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame with duplicate data\n",
    "data = {\n",
    "    'Customer_ID': [101, 102, 103, 101, 104, 102],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'David', 'Bob'],\n",
    "    'Address': ['123 Main St', '456 Pine St', '789 Oak St', '123 Main St', '321 Cedar St', '456 Pine St']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Removing duplicates based on the 'Customer_ID' column\n",
    "df_no_duplicates_by_id = df.drop_duplicates(subset=['Customer_ID'])\n",
    "print(\"\\nDataFrame after Removing Duplicates Based on 'Customer_ID':\")\n",
    "print(df_no_duplicates_by_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcfcdd",
   "metadata": {},
   "source": [
    "### Keeping the Last Occurrence of Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates but keeping the last occurrence of each duplicate\n",
    "df_keep_last = df.drop_duplicates(subset=['Customer_ID', 'Name', 'Address'], keep='last')\n",
    "print(\"\\nDataFrame after Removing Duplicates, Keeping Last Occurrence:\")\n",
    "print(df_keep_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e25b3",
   "metadata": {},
   "source": [
    "### You want to identify outliers in a dataset containing exam scores using the Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Example data\n",
    "data = {'score': [50, 55, 40, 100, 45]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculating Z-scores\n",
    "df['z_score'] = zscore(df['score'])\n",
    "\n",
    "# Identifying outliers (e.g., |z_score| > 2)\n",
    "outliers = df[np.abs(df['z_score']) > 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388c94d",
   "metadata": {},
   "source": [
    "### You want to identify multivariate outliers in a dataset containing height and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296730c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "data = {'height': [170, 180, 150, 200], 'weight': [70, 80, 50, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Computing Mahalanobis distance\n",
    "cov_matrix = np.cov(df, rowvar=False)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "mean = df.mean()\n",
    "mahalanobis_dist = df.apply(lambda x: distance.mahalanobis(x, mean, inv_cov_matrix), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f2fdb",
   "metadata": {},
   "source": [
    "### Removing outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'height': [150, 160, 50, 270, 180]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Removing outliers\n",
    "df = df[(df['height'] >= 100) & (df['height'] <= 250)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310053c",
   "metadata": {},
   "source": [
    "### Transformation of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "data = {'salary': [30000, 40000, 2000000, 50000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Log transforming the 'salary' column\n",
    "df['log_salary'] = np.log(df['salary'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa0373a",
   "metadata": {},
   "source": [
    "### Imputing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b04c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "data = {'age': [25, 30, 120, 22, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Replacing outliers with median\n",
    "median_age = df['age'].median()\n",
    "df['age'] = np.where((df['age'] < 18) | (df['age'] > 100), median_age, df['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b398b7",
   "metadata": {},
   "source": [
    "### Handling inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ddb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'country': ['USA', 'U.S.A.', 'United States', 'UK', 'U.K.']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standardizing the country names\n",
    "df['country'] = df['country'].replace(['USA', 'U.S.A.'], 'United States').replace(['UK', 'U.K.'], 'United Kingdom')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72326584",
   "metadata": {},
   "source": [
    "### Converting categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6dbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "data = {'Response': ['Yes', 'No', 'Yes', 'No']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Converting 'Yes' and 'No' to 1 and 0\n",
    "df['Response'] = df['Response'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf26c9",
   "metadata": {},
   "source": [
    "### Normalizing numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Example data\n",
    "data = {'price': [5, 100, 20], 'quantity': [10, 1000, 100]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "df[['price', 'quantity']] = scaler.fit_transform(df[['price', 'quantity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86fcbc7",
   "metadata": {},
   "source": [
    "### Range checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ba8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'grades': [95, 50, 150, 88, -10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying range checks to flag invalid grades\n",
    "df['invalid_grade'] = (df['grades'] < 0) | (df['grades'] > 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2849a8",
   "metadata": {},
   "source": [
    "### Pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c346d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Example data\n",
    "data = {'email': ['john@example.com', 'sarah.example', 'david@example']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Defining a pattern for valid email addresses\n",
    "pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "\n",
    "# Applying pattern matching to flag invalid emails\n",
    "df['invalid_email'] = df['email'].apply(lambda x: not bool(re.match(pattern, x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b7a769",
   "metadata": {},
   "source": [
    "### Consistency checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "data = {'initial_stock': [100, 50, 200], 'sales': [50, 60, 150], 'replenished': [0, 20, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Checking if sales exceed stock levels\n",
    "df['inconsistent_data'] = (df['sales'] > (df['initial_stock'] + df['replenished']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
